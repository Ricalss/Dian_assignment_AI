材料学院——冯雄飞的文档

数据集:

分为训练集与测试集，分类问题中一般有相应的标签集。
一般的分类问题中：训练集用于输入到预测模型，得到输出，评价输出（损失函数），以及反向优化模型中的参数，使得预测效果更好。

模型：

人为设计的一种复杂函数，以达到相关的数据输入到这个模型中，该模型可以得到一个映射的值（该值用来反映输入数据的某种数据）。比如MNIST集中，输入一张图片，模型输出一个值来表达这张图片是哪个数字。然而这种函数很难认为创造，设计者只能创建一个架构，如CNN模型，但是当中无数的参数无法人工确定。参数初始随机赋值，后续优化都交给训练集和优化器。当确定函数的构架，优化器优化其中的参数，得到适合的参数，这就是个优秀的预测模型。

优化器：

优化器是利用模型中数据，以及输出的评价，反向优化模型中的参数。一般而言采用反向传播，计算各参数的梯度，再取所有可变参数的梯度值的负值乘上学习率（梯度的负值才是使损失函数值减小的方向），更改模型中的参数。反向传播、计算梯度是优化器中最重要的部分。

损失函数：

损失函数是用来评价模型预测结果的好坏的函数，常用的有交叉熵函数、softmax函数等等。交叉熵函数整合了softmax、log、NLLloss函数，其值越小说明模型预测效果越好。反向传播时计算梯度就是从损失函数的输出值loss开始的。

关于CNN模型：
   CNN层数越多，预测能力越强，预测问题越复杂
   笔者将卷积层与池化层看做一层，有些人将池化层单独做一层。

笔者设计的CNN模型：

正向传播：

layer1：卷积层--(bs, 1, 28, 28)-->规范化输出--(bs, 16, 28, 28)-->池化层--(bs, 16, 14, 14 )-->layer2

layer2:卷积层--(bs, 16, 14, 14)-->--(bs, 32, 14, 14)-->池化层--(bs, 32, 7, 7 )-->reshape

reshape--(bs, 32*7*7)-->layer3

layer3:线性层--(bs, 10)--规范化输出-->交叉熵函数

CrossEntropyLoss()--->Loss

反向传播：上述过程逆向即为反向传播

